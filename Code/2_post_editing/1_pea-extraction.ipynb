{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PEA Extraction (Post-Editing Actions)\n",
    "\n",
    "Based on Blain et al. 2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom as minidom\n",
    "import spacy\n",
    "import language_tool_python\n",
    "\n",
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "tool = language_tool_python.LanguageTool(\"it-IT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of MT sentences from WebNLG-IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47191\n"
     ]
    }
   ],
   "source": [
    "triple_numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n",
    "dataset_types = [\"test\", \"dev\", \"train\"]\n",
    "\n",
    "dataset = []\n",
    "for dataset_type in dataset_types:\n",
    "    if (dataset_type == \"test\"):\n",
    "        path = \"..\\\\..\\\\WebNLG\\\\it\\\\test\"\n",
    "\n",
    "        file_names = []\n",
    "        for file_name in os.listdir(path):\n",
    "            if os.path.isfile(os.path.join(path, file_name)):\n",
    "                url = os.path.join(path, file_name)\n",
    "                tree = ET.parse(url)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for entry in root.iter('entry'):\n",
    "                    originaltripleset = entry.find('modifiedtripleset')\n",
    "                    otriple = originaltripleset.find('mtriple')\n",
    "\n",
    "                    for lex in entry.iter('lex'):\n",
    "                        if lex.get('lang') == \"it\":\n",
    "                            dataset.append((otriple.text, lex.text))\n",
    "    else:\n",
    "        for triple_number in triple_numbers:\n",
    "            path = \"..\\\\..\\\\WebNLG\\\\it\\\\\" + dataset_type + \"\\\\\" + triple_number + \"triples\"\n",
    "\n",
    "            file_names = []\n",
    "            for file_name in os.listdir(path):\n",
    "                if os.path.isfile(os.path.join(path, file_name)):\n",
    "                    url = os.path.join(path, file_name)\n",
    "                    tree = ET.parse(url)\n",
    "                    root = tree.getroot()\n",
    "\n",
    "\n",
    "                    for entry in root.iter('entry'):\n",
    "                        originaltripleset = entry.find('modifiedtripleset')\n",
    "                        otriple = originaltripleset.find('mtriple')\n",
    "\n",
    "                        for lex in entry.iter('lex'):\n",
    "                            if lex.get('lang') == \"it\":\n",
    "                                dataset.append((otriple.text, lex.text))\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the KB containing false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open false-positive-manual-pe.csv into array ner\n",
    "ner = []\n",
    "with open('datasets/false-positive.csv', 'r', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        ner.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Detection Loop\n",
    "\n",
    "It utilizes a combination of:\n",
    "\n",
    "<ul>\n",
    "    <li>Language Tool Python</li>\n",
    "    <li>Spacy</li>\n",
    "    <li>false-positive.csv</li>\n",
    "</ul>\n",
    "\n",
    "By analyzing the output generated by this code, the file 'errors.txt' was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['estádio', 'municipal', 'coaracy', 'mata', 'fonseca', 'agremiação', 'sportiva', 'arapiraquense', 'arapiraca', 'agremiação', 'sportiva', 'arapiraquense', 'alvinegro', 'campeonato', 'brasileiro', 'série', 'c', 'brasile']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for _, text in dataset:\n",
    "    doc = nlp(text)\n",
    "\n",
    "    nes = []\n",
    "    for ent in doc.ents:\n",
    "        nes.extend(ent.text.lower().split(\" \"))\n",
    "\n",
    "    matches = tool.check(text)\n",
    "\n",
    "    if len(matches) > 0:\n",
    "        for match in matches:\n",
    "            if (match.ruleId != \"UPPERCASE_SENTENCE_START\"):\n",
    "                error_text = text[match.offset:match.errorLength + match.offset]\n",
    "                if error_text.lower() not in nes and error_text.lower() not in ner:\n",
    "                    print('Errore n. ' + str(j))\n",
    "                    print(error_text.lower(), nes)\n",
    "                    print(\"Errors found for sentence \" + str(i))\n",
    "                    print(f\"Rule ID: {match.ruleId}\")\n",
    "                    print(f\"Error: {match.message}\")\n",
    "                    print(f\"Suggested correction: {match.replacements}\")\n",
    "                    print(f\"Error: {text[match.offset:match.errorLength + match.offset]}\")\n",
    "                    print(f\"Relative sentence: {text}\")\n",
    "                    print(f\"Relative triple: {dataset[i][0]}\")\n",
    "                    print(f\"ne: {nes}\")\n",
    "                    print('\\n')\n",
    "                    j += 1\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(nes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
