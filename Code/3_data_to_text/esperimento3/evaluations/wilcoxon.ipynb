{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.stats import wilcoxon\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('bleu_scores-exp3.pkl', 'rb') as f:\n",
    "    bleu_scores = pickle.load(f)\n",
    "\n",
    "with open('meteor_scores-exp3.pkl', 'rb') as f:\n",
    "    meteor_scores = pickle.load(f)\n",
    "\n",
    "with open('chrf_scores-exp3.pkl', 'rb') as f:\n",
    "    chrf_scores = pickle.load(f)\n",
    "\n",
    "with open('bertscore_scores-exp3.pkl', 'rb') as f:\n",
    "    bertscore_scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageScores(scores):\n",
    "    for lang in scores:\n",
    "        for model in scores[lang]:\n",
    "            averages = []\n",
    "            for i in range(len(scores[lang][model][0])):\n",
    "                average = (scores[lang][model][0][i] + scores[lang][model][1][i] + scores[lang][model][2][i]) / 3\n",
    "                averages.append(average)\n",
    "            scores[lang][model] = averages\n",
    "    return scores\n",
    "\n",
    "bleu_scores = averageScores(bleu_scores)\n",
    "meteor_scores = averageScores(meteor_scores)\n",
    "chrf_scores = averageScores(chrf_scores)\n",
    "bertscore_scores = averageScores(bertscore_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_tests(metric_scores):\n",
    "    alpha = 0.05  # Soglia di significatività\n",
    "    print(\"\\n===== STATISTICAL TESTS =====\")\n",
    "\n",
    "    for lang in metric_scores:\n",
    "        print(f\"\\n### Language: {lang} ###\")\n",
    "        scores = metric_scores[lang]\n",
    "        model_names = list(scores.keys())\n",
    "        model_data = {model: np.array(scores[model]) for model in model_names}\n",
    "\n",
    "        # calcola la media\n",
    "        for model in model_names:\n",
    "            print(f\" - {model}: {model_data[model].mean():.4f}\")\n",
    "\n",
    "        # Test post-hoc Wilcoxon\n",
    "        for model_a, model_b in combinations(model_names, 2):\n",
    "            stat, p_val = wilcoxon(model_data[model_a], model_data[model_b])\n",
    "            print(f\" - {model_a} vs {model_b}: Wilcoxon statistic={stat:.4f}, p-value={p_val:.4f}\")\n",
    "\n",
    "            if p_val < alpha:\n",
    "                print(f\"   → Differenza significativa tra {model_a} e {model_b}.\")\n",
    "            else:\n",
    "                print(f\"   → Nessuna differenza significativa tra {model_a} e {model_b}.\\n\")\n",
    "       \n",
    "        print(\"\\n\" + \"#\" * 40)  # Separatore per le lingue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU\n",
      "\n",
      "===== STATISTICAL TESTS =====\n",
      "\n",
      "### Language: it ###\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it: 0.5112\n",
      " - Llama-3.1-8B-Instruct-it: 0.5180\n",
      " - Minerva-7B-instruct-v1.0-it: 0.4438\n",
      " - Mistral-Nemo-Instruct-2407-it: 0.5430\n",
      " - Qwen2.5-7B-Instruct-it: 0.4693\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Llama-3.1-8B-Instruct-it: Wilcoxon statistic=514951.5000, p-value=0.1368\n",
      "   → Nessuna differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Llama-3.1-8B-Instruct-it.\n",
      "\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=419090.0000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Minerva-7B-instruct-v1.0-it.\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=480205.0000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=468104.5000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Qwen2.5-7B-Instruct-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=417837.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Minerva-7B-instruct-v1.0-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=501390.5000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=464420.5000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Qwen2.5-7B-Instruct-it.\n",
      " - Minerva-7B-instruct-v1.0-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=328104.5000, p-value=0.0000\n",
      "   → Differenza significativa tra Minerva-7B-instruct-v1.0-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - Minerva-7B-instruct-v1.0-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=557192.5000, p-value=0.0000\n",
      "   → Differenza significativa tra Minerva-7B-instruct-v1.0-it e Qwen2.5-7B-Instruct-it.\n",
      " - Mistral-Nemo-Instruct-2407-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=373256.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Mistral-Nemo-Instruct-2407-it e Qwen2.5-7B-Instruct-it.\n",
      "\n",
      "########################################\n",
      "\n",
      "METEOR\n",
      "\n",
      "===== STATISTICAL TESTS =====\n",
      "\n",
      "### Language: it ###\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it: 0.7285\n",
      " - Llama-3.1-8B-Instruct-it: 0.7317\n",
      " - Minerva-7B-instruct-v1.0-it: 0.6986\n",
      " - Mistral-Nemo-Instruct-2407-it: 0.7416\n",
      " - Qwen2.5-7B-Instruct-it: 0.7136\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Llama-3.1-8B-Instruct-it: Wilcoxon statistic=551443.5000, p-value=0.1963\n",
      "   → Nessuna differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Llama-3.1-8B-Instruct-it.\n",
      "\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=517188.5000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Minerva-7B-instruct-v1.0-it.\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=517591.0000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=566630.5000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Qwen2.5-7B-Instruct-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=516551.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Minerva-7B-instruct-v1.0-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=545842.5000, p-value=0.0002\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=562447.5000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Qwen2.5-7B-Instruct-it.\n",
      " - Minerva-7B-instruct-v1.0-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=447754.5000, p-value=0.0000\n",
      "   → Differenza significativa tra Minerva-7B-instruct-v1.0-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - Minerva-7B-instruct-v1.0-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=607532.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Minerva-7B-instruct-v1.0-it e Qwen2.5-7B-Instruct-it.\n",
      " - Mistral-Nemo-Instruct-2407-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=475457.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Mistral-Nemo-Instruct-2407-it e Qwen2.5-7B-Instruct-it.\n",
      "\n",
      "########################################\n",
      "\n",
      "CHRF\n",
      "\n",
      "===== STATISTICAL TESTS =====\n",
      "\n",
      "### Language: it ###\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it: 62.2772\n",
      " - Llama-3.1-8B-Instruct-it: 62.3841\n",
      " - Minerva-7B-instruct-v1.0-it: 60.0844\n",
      " - Mistral-Nemo-Instruct-2407-it: 63.4067\n",
      " - Qwen2.5-7B-Instruct-it: 61.1452\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Llama-3.1-8B-Instruct-it: Wilcoxon statistic=569224.0000, p-value=0.2445\n",
      "   → Nessuna differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Llama-3.1-8B-Instruct-it.\n",
      "\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=519075.0000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Minerva-7B-instruct-v1.0-it.\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=504274.0000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=582445.0000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Qwen2.5-7B-Instruct-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=516564.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Minerva-7B-instruct-v1.0-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=532331.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=571713.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Qwen2.5-7B-Instruct-it.\n",
      " - Minerva-7B-instruct-v1.0-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=429479.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Minerva-7B-instruct-v1.0-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - Minerva-7B-instruct-v1.0-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=622919.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Minerva-7B-instruct-v1.0-it e Qwen2.5-7B-Instruct-it.\n",
      " - Mistral-Nemo-Instruct-2407-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=461225.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Mistral-Nemo-Instruct-2407-it e Qwen2.5-7B-Instruct-it.\n",
      "\n",
      "########################################\n",
      "\n",
      "BERTScore\n",
      "\n",
      "===== STATISTICAL TESTS =====\n",
      "\n",
      "### Language: it ###\n",
      " - Llama-3.1-8B-Instruct-it: 0.9036\n",
      " - Mistral-Nemo-Instruct-2407-it: 0.9071\n",
      " - Qwen2.5-7B-Instruct-it: 0.8948\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it: 0.9028\n",
      " - Minerva-7B-instruct-v1.0-it: 0.8888\n",
      " - Llama-3.1-8B-Instruct-it vs Mistral-Nemo-Instruct-2407-it: Wilcoxon statistic=563611.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Mistral-Nemo-Instruct-2407-it.\n",
      " - Llama-3.1-8B-Instruct-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=524179.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Qwen2.5-7B-Instruct-it.\n",
      " - Llama-3.1-8B-Instruct-it vs LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it: Wilcoxon statistic=578046.0000, p-value=0.0919\n",
      "   → Nessuna differenza significativa tra Llama-3.1-8B-Instruct-it e LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it.\n",
      "\n",
      " - Llama-3.1-8B-Instruct-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=451768.5000, p-value=0.0000\n",
      "   → Differenza significativa tra Llama-3.1-8B-Instruct-it e Minerva-7B-instruct-v1.0-it.\n",
      " - Mistral-Nemo-Instruct-2407-it vs Qwen2.5-7B-Instruct-it: Wilcoxon statistic=431367.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Mistral-Nemo-Instruct-2407-it e Qwen2.5-7B-Instruct-it.\n",
      " - Mistral-Nemo-Instruct-2407-it vs LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it: Wilcoxon statistic=552695.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Mistral-Nemo-Instruct-2407-it e LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it.\n",
      " - Mistral-Nemo-Instruct-2407-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=380917.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Mistral-Nemo-Instruct-2407-it e Minerva-7B-instruct-v1.0-it.\n",
      " - Qwen2.5-7B-Instruct-it vs LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it: Wilcoxon statistic=538135.5000, p-value=0.0000\n",
      "   → Differenza significativa tra Qwen2.5-7B-Instruct-it e LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it.\n",
      " - Qwen2.5-7B-Instruct-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=606981.0000, p-value=0.0000\n",
      "   → Differenza significativa tra Qwen2.5-7B-Instruct-it e Minerva-7B-instruct-v1.0-it.\n",
      " - LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it vs Minerva-7B-instruct-v1.0-it: Wilcoxon statistic=446198.5000, p-value=0.0000\n",
      "   → Differenza significativa tra LLaMAntino-3-ANITA-8B-Inst-DPO-ITA-it e Minerva-7B-instruct-v1.0-it.\n",
      "\n",
      "########################################\n"
     ]
    }
   ],
   "source": [
    "print('BLEU')\n",
    "statistical_tests(bleu_scores)\n",
    "print()\n",
    "\n",
    "print('METEOR')\n",
    "statistical_tests(meteor_scores)\n",
    "print()\n",
    "\n",
    "print('CHRF')\n",
    "statistical_tests(chrf_scores)\n",
    "print()\n",
    "\n",
    "print('BERTScore')\n",
    "statistical_tests(bertscore_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
