{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    'pre_splitted_test',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(dict1, dict2):\n",
    "    #print(f'START MERGE_DICTS')\n",
    "    merged_dict = {}\n",
    "    for key, value in dict1.items():\n",
    "        merged_dict[key] = dict1[key]\n",
    "\n",
    "        if key in dict2:\n",
    "            for triple in value:\n",
    "                flag = True\n",
    "                for key, value in merged_dict.items():\n",
    "                    if triple in value:\n",
    "                        flag = False\n",
    "                        break\n",
    "\n",
    "                if flag:\n",
    "                    merged_dict[key].insert(0, triple)\n",
    "        else:\n",
    "            merged_dict[key] = value\n",
    "\n",
    "    keys = list(merged_dict.keys())\n",
    "    values = list(merged_dict.values())\n",
    "    keys = [str(i) for i in range(len(keys))]\n",
    "    merged_dict = dict(zip(keys, values))\n",
    "\n",
    "    #print(f'END MERGE_DICTS')\n",
    "    return merged_dict\n",
    "\n",
    "def split_mixed(triples):\n",
    "    subject_dict = {}\n",
    "    object_dict = {}\n",
    "    #print(f'START SPLIT_MIXED')\n",
    "    for triple in triples:\n",
    "        triple = triple.split(' ')\n",
    "\n",
    "        if len(triple) > 1:\n",
    "            # sibling\n",
    "            subject = triple[0]\n",
    "\n",
    "            if subject in subject_dict:\n",
    "                subject_dict[subject].append(triple)\n",
    "            else:\n",
    "                subject_dict[subject] = [triple]\n",
    "\n",
    "            # chain\n",
    "            object = triple[0]\n",
    "\n",
    "            for triple in triples:\n",
    "                triple = triple.split(' ')\n",
    "\n",
    "                if len(triple) > 1:\n",
    "                    if triple[2] == object:\n",
    "                        if object in object_dict:\n",
    "                            object_dict[object].append(triple)\n",
    "                        else:\n",
    "                            object_dict[object] = [triple]\n",
    "\n",
    "    #print(f'subject_dict: {subject_dict}')\n",
    "    #print(f'object_dict: {object_dict}')\n",
    "\n",
    "    merged_dict = merge_dicts(subject_dict, object_dict)\n",
    "\n",
    "    #print(f'END SPLIT_MIXED')\n",
    "    return merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitta il dizionario in gruppi di 3 nel caso ci fossero chiavi con piu di 3 valori\n",
    "def split_dict(dict_to_split):\n",
    "    new_dict = {}\n",
    "    for key, value in dict_to_split.items():\n",
    "        num_chunks = (len(value) + 2) // 3  # Calcoliamo il numero di chunk necessari\n",
    "        for i in range(num_chunks):\n",
    "            new_key = f\"{key}_{i}\" if i > 0 else key  # Creiamo una nuova chiave con indice se necessario\n",
    "            start = i * 3\n",
    "            end = min((i + 1) * 3, len(value))\n",
    "            new_dict[new_key] = value[start:end]  # Aggiungiamo i valori corrispondenti\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_with_max_values(array, max_values_per_key):\n",
    "    array = [triple for triple in array if triple.strip()]  # Rimuovi le stringhe vuote\n",
    "    result_dict = {}\n",
    "    current_key_index = 0\n",
    "    current_key_values = []\n",
    "    for triple in array:\n",
    "        current_key_values.append(triple.split(' '))\n",
    "        if len(current_key_values) == max_values_per_key:\n",
    "            result_dict[current_key_index] = current_key_values\n",
    "            current_key_index += 1\n",
    "            current_key_values = []\n",
    "    # Aggiungi eventuali valori rimanenti\n",
    "    if current_key_values:\n",
    "        result_dict[current_key_index] = current_key_values\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_name in dataset_names:\n",
    "    print(f'Processing {dataset_name}')\n",
    "    full_dataset = pd.read_csv(f'datasets/{dataset_name}.csv')\n",
    "    dataset = full_dataset.sample(frac=1, random_state=42)\n",
    "    dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    triples_dict = {}\n",
    "    j = 0\n",
    "    for i in range(len(dataset)):\n",
    "        triples = dataset['triple'][i].split(' | ')\n",
    "\n",
    "        if (dataset['shape_type'][i] == 'mixed' or dataset['shape_type'][i] == 'NA' or dataset['shape_type'][i] == 'unknown') and dataset['size'][i] > 2:\n",
    "            dictionary = split_mixed(triples)\n",
    "            dictionary = split_dict(dictionary)\n",
    "        else:\n",
    "            dictionary = create_dict_with_max_values(triples, 3)\n",
    "            \n",
    "        for key, value in dictionary.items():\n",
    "            value_text = ''\n",
    "            for triple in value:\n",
    "                value_text += ' '.join(triple) + ' '\n",
    "\n",
    "            triples_dict[j] = {\n",
    "                'id': i,\n",
    "                'triples': value_text,\n",
    "                'data_unit' : dataset['triple'][i],\n",
    "                'shape' : dataset['shape'][i],\n",
    "                'shape_type' : dataset['shape_type'][i],\n",
    "                'local_size' : len(value),\n",
    "                'size' : dataset['size'][i],\n",
    "            }\n",
    "            j += 1\n",
    "\n",
    "    triples_df = pd.DataFrame.from_dict(triples_dict, \"index\")\n",
    "    triples_df.to_csv(f'splitted_test.csv', index=False)\n",
    "\n",
    "    triples_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dict(dict_to_split):\n",
    "    new_dict = {}\n",
    "    for key, value in dict_to_split.items():\n",
    "        num_chunks = (len(value) + 2) // 3  # Calcoliamo il numero di chunk necessari\n",
    "        for i in range(num_chunks):\n",
    "            new_key = f\"{key}_{i}\" if i > 0 else key  # Creiamo una nuova chiave con indice se necessario\n",
    "            start = i * 3\n",
    "            end = min((i + 1) * 3, len(value))\n",
    "            new_dict[new_key] = value[start:end]  # Aggiungiamo i valori corrispondenti\n",
    "    return new_dict\n",
    "\n",
    "dict_to_split = {'0': [['William_Anders', 'mission', 'Apollo_8'], ['Apollo_8', 'crew1Up', 'Frank_Borman'], ['Apollo_8', 'crew2Up', 'Buzz_Aldrin'], ['Apollo_8', 'operator', 'NASA']]}\n",
    "\n",
    "split_dict_result = split_dict(dict_to_split)\n",
    "\n",
    "for key, value in split_dict_result.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
