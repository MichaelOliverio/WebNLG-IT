{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "#bleu \n",
    "from evaluate import load\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "#ter\n",
    "from torchmetrics.text import TranslationEditRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open files in generations directory\n",
    "def open_files(directory):\n",
    "    files = os.listdir(directory)\n",
    "    files.sort()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "files = open_files('generations')\n",
    "for file in files:\n",
    "    dataset = pd.read_csv('generations/' + file)\n",
    "    datasets[file] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llama2_7b_it_2epoch_decoding.csv',\n",
       " 'llama2_7b_it_sa_1shot_2epoch_decoding.csv',\n",
       " 'llama2_7b_it_sa_2epoch_decoding.csv',\n",
       " 'llamantino2_7b_it_2epoch_decoding.csv',\n",
       " 'llamantino2_7b_it_sa_2epoch_decoding.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['llama2_7b_it_sa_1shot_2epoch_decoding.csv']['actuals'] =  datasets['llama2_7b_it_2epoch_decoding.csv']['actuals']\n",
    "datasets['llama2_7b_it_sa_2epoch_decoding.csv']['actuals'] =  datasets['llama2_7b_it_2epoch_decoding.csv']['actuals']\n",
    "datasets['llamantino2_7b_it_sa_2epoch_decoding.csv']['actuals'] =  datasets['llama2_7b_it_2epoch_decoding.csv']['actuals']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione automatica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacrebleu = load(\"sacrebleu\")\n",
    "\n",
    "def blue_evaluation(df):\n",
    "    blue_scores = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        reference = df['actuals'][i].lower()\n",
    "        candidate = df['predictions'][i].lower()\n",
    "\n",
    "        blue_score = sacrebleu.compute(predictions=[candidate], references=[reference])\n",
    "        blue_scores.append(float(blue_score['score']))\n",
    "        \n",
    "    return blue_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU SCORES: \n",
      "\n",
      "- llama2_7b_it_2epoch_decoding.csv:\n",
      "    30.947234161431346\n",
      "\n",
      "\n",
      "- llama2_7b_it_sa_1shot_2epoch_decoding.csv:\n",
      "    28.540514495575252\n",
      "\n",
      "\n",
      "- llama2_7b_it_sa_2epoch_decoding.csv:\n",
      "    28.553936917262842\n",
      "\n",
      "\n",
      "- llamantino2_7b_it_2epoch_decoding.csv:\n",
      "    32.92150384048398\n",
      "\n",
      "\n",
      "- llamantino2_7b_it_sa_2epoch_decoding.csv:\n",
      "    31.792868267825543\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('BLEU SCORES: \\n')\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(f'- {dataset_name}:')\n",
    "\n",
    "    datasets[dataset_name]['bleu_score'] = blue_evaluation(datasets[dataset_name])\n",
    "    print(f\"    {datasets[dataset_name]['bleu_score'].mean()}\")\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "def bertscore_evaluation(actual, prediction, lang):\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        predictions.append(prediction.iloc[i].lower())\n",
    "        references.append(actual.iloc[i].lower())\n",
    "\n",
    "    bertscore_scores = bertscore.compute(predictions=predictions, references=references, lang=lang)\n",
    "\n",
    "    return bertscore_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTSCORE SCORES: \n",
      "\n",
      "- llama2_7b_it_2epoch_decoding.csv (it):\n",
      "-F1:  0.8596069986224174\n",
      "-P:  0.8620031984448433\n",
      "-R:  0.8576335867643357\n",
      "\n",
      "\n",
      "- llama2_7b_it_sa_1shot_2epoch_decoding.csv (it):\n",
      "-F1:  0.849708055794239\n",
      "-P:  0.8578462609648705\n",
      "-R:  0.8427860285043717\n",
      "\n",
      "\n",
      "- llama2_7b_it_sa_2epoch_decoding.csv (it):\n",
      "-F1:  0.8480962705612183\n",
      "-P:  0.8542063003778457\n",
      "-R:  0.8431392735242844\n",
      "\n",
      "\n",
      "- llamantino2_7b_it_2epoch_decoding.csv (it):\n",
      "-F1:  0.8632007264494896\n",
      "-P:  0.8663134371042251\n",
      "-R:  0.8605485225915909\n",
      "\n",
      "\n",
      "- llamantino2_7b_it_sa_2epoch_decoding.csv (it):\n",
      "-F1:  0.8580915243625641\n",
      "-P:  0.8621243567466735\n",
      "-R:  0.8546362680196762\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('BERTSCORE SCORES: \\n')\n",
    "\n",
    "for dataset_name in datasets:\n",
    "\n",
    "    print(f'- {dataset_name} (it):')\n",
    "\n",
    "    score = bertscore_evaluation(datasets[dataset_name]['actuals'], datasets[dataset_name]['predictions'], 'it')\n",
    "    datasets[dataset_name]['bertscore_f1'] = score['f1']\n",
    "    datasets[dataset_name]['bertscore_precision'] = score['precision']\n",
    "    datasets[dataset_name]['bertscore_recall'] = score['recall']\n",
    "    #print(score)\n",
    "    \n",
    "    print(f'-F1: ', np.mean(score['f1']))\n",
    "    print(f'-P: ', np.mean(score['precision']))\n",
    "    print(f'-R: ', np.mean(score['recall']))\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ter = TranslationEditRate()\n",
    "\n",
    "def ter_evaluation(actual, prediction):\n",
    "    ter_scores = []\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        reference = actual.iloc[i].lower()\n",
    "        candidate = prediction.iloc[i].lower()\n",
    "\n",
    "        ter_score = ter(candidate, [reference])\n",
    "        ter_scores.append(ter_score)\n",
    "\n",
    "    return ter_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TER SCORES: \n",
      "\n",
      "- llama2_7b_it_2epoch_decoding.csv:\n",
      "    0.7037606201171875\n",
      "\n",
      "\n",
      "- llama2_7b_it_sa_1shot_2epoch_decoding.csv:\n",
      "    0.690429443359375\n",
      "\n",
      "\n",
      "- llama2_7b_it_sa_2epoch_decoding.csv:\n",
      "    0.7054981689453125\n",
      "\n",
      "\n",
      "- llamantino2_7b_it_2epoch_decoding.csv:\n",
      "    0.6816765747070312\n",
      "\n",
      "\n",
      "- llamantino2_7b_it_sa_2epoch_decoding.csv:\n",
      "    0.6700052490234375\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TER SCORES: \\n')\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(f'- {dataset_name}:')\n",
    "    datasets[dataset_name]['ter'] = ter_evaluation(datasets[dataset_name]['actuals'], datasets[dataset_name]['predictions'])\n",
    "    print(f\"    {datasets[dataset_name]['ter'].mean()}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf = load(\"chrf\")\n",
    "\n",
    "def chrf_evaluation(actual, prediction):\n",
    "    chrf_scores = []\n",
    "\n",
    "    # Utilizza tqdm per monitorare lo stato di avanzamento\n",
    "    for i in tqdm(range(len(actual)), desc=\"Calcolo CHRF\"):\n",
    "        reference = actual.iloc[i].lower()\n",
    "        candidate = prediction.iloc[i].lower()\n",
    "        chrf_score = chrf.compute(predictions=[candidate], references=[reference])['score']\n",
    "\n",
    "        chrf_scores.append(chrf_score)\n",
    "\n",
    "    return chrf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHRF SCORES: \n",
      "\n",
      "- llama2_7b_it_2epoch_decoding.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo CHRF: 100%|██████████| 1000/1000 [00:20<00:00, 47.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    62.517357889450736\n",
      "\n",
      "\n",
      "- llama2_7b_it_sa_1shot_2epoch_decoding.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo CHRF: 100%|██████████| 1000/1000 [00:19<00:00, 50.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    59.2446339810021\n",
      "\n",
      "\n",
      "- llama2_7b_it_sa_2epoch_decoding.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo CHRF: 100%|██████████| 1000/1000 [00:18<00:00, 52.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    59.50446659679372\n",
      "\n",
      "\n",
      "- llamantino2_7b_it_2epoch_decoding.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo CHRF: 100%|██████████| 1000/1000 [00:21<00:00, 46.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    63.580743422030515\n",
      "\n",
      "\n",
      "- llamantino2_7b_it_sa_2epoch_decoding.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo CHRF: 100%|██████████| 1000/1000 [00:20<00:00, 48.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    62.98687214051879\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CHRF SCORES: \\n')\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(f'- {dataset_name}:')\n",
    "    datasets[dataset_name]['chrf'] = chrf_evaluation(datasets[dataset_name]['actuals'], datasets[dataset_name]['predictions'])\n",
    "    print(f\"    {datasets[dataset_name]['chrf'].mean()}\")\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
