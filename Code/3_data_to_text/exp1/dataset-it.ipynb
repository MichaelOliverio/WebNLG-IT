{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Costruzioni dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sentencepiece as spm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom as minidom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset per RDF2Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train e dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39890\n"
     ]
    }
   ],
   "source": [
    "dataset_types = [\"train\", \"dev\"] \n",
    "triple_numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n",
    "\n",
    "i = 0\n",
    "for dataset_type in dataset_types:\n",
    "    dataset = []\n",
    "\n",
    "    for triple_number in triple_numbers:\n",
    "        path = \"..\\\\..\\\\webnlg\\\\it-PE\\\\\" + dataset_type + \"\\\\\" + triple_number + \"triples\"\n",
    "        file_names = []\n",
    "        for file_name in os.listdir(path):\n",
    "            if os.path.isfile(os.path.join(path, file_name)):\n",
    "                url = os.path.join(path, file_name)\n",
    "                tree = ET.parse(url)\n",
    "                root = tree.getroot()\n",
    "\n",
    "                for entry in root.iter('entry'):\n",
    "                    mts = []\n",
    "\n",
    "                    eid = entry.get('eid')\n",
    "                    category = entry.get('category')\n",
    "                    shape = entry.get('shape')\n",
    "                    shape_type = entry.get('shape_type')\n",
    "                    size = entry.get('size')\n",
    "                    \n",
    "                    for modifiedtripleset in entry.iter('modifiedtripleset'):\n",
    "                        mtriples = \"\"\n",
    "\n",
    "                        # con ordinamento alfabetico\n",
    "                        triples = []\n",
    "                        for mtriple in modifiedtripleset.iter('mtriple'):  \n",
    "                            triple = mtriple.text.split(\" | \")\n",
    "                            triple = (triple[0], triple[1], triple[2])\n",
    "                            triples.append(triple)\n",
    "\n",
    "                        triples.sort(key=lambda x: x[1])\n",
    "                        for triple in triples:\n",
    "                            mtriples += triple[0] + \" \" + triple[1] + \" \" + triple[2] + \" \"\n",
    "\n",
    "                        # if last character is space remove it\n",
    "                        if mtriples[-1] == \" \":\n",
    "                            mtriples = mtriples[:-1]\n",
    "                            mts.append(mtriples)\n",
    "\n",
    "\n",
    "                        mts.append(mtriples)\n",
    "\n",
    "                    lexs = []\n",
    "                    for lex in entry.iter('lex'):\n",
    "                        if lex.get('lang') == \"it-PE\":\n",
    "                            lexs.append(lex.text)\n",
    "\n",
    "                    for lex in lexs:\n",
    "                        i += 1\n",
    "                        dataset.append([size, file_name, eid, category, shape, shape_type, mts[0], lex])\n",
    "\n",
    "    df_dataset = pd.DataFrame(dataset)\n",
    "    df_dataset.columns = [\"num_triples\", \"file_name\", \"eid\", \"category\", \"shape\", \"shape_type\", \"data_unit\", \"sentence\"]\n",
    "    df_dataset.to_csv(\"datasets\\\\it-PE\\\\\" + dataset_type + \".csv\", index=False)\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "path = \"..\\\\..\\\\webnlg\\\\it-PE\\\\test\"\n",
    "file_name = \"rdf-to-text-generation-test-data-with-refs-en.xml\"\n",
    "\n",
    "if os.path.isfile(os.path.join(path, file_name)):\n",
    "    url = os.path.join(path, file_name)\n",
    "    tree = ET.parse(url)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for entry in root.iter('entry'):\n",
    "        mts = []\n",
    "        \n",
    "        eid = entry.get('eid')\n",
    "        category = entry.get('category')\n",
    "        shape = entry.get('shape')\n",
    "        shape_type = entry.get('shape_type')\n",
    "        size = entry.get('size')\n",
    "\n",
    "        for modifiedtripleset in entry.iter('modifiedtripleset'):\n",
    "            mtriples = \"\"\n",
    "\n",
    "            # Con ordinamento alfabetico\n",
    "            triples = []\n",
    "            for mtriple in modifiedtripleset.iter('mtriple'):  \n",
    "                triple = mtriple.text.split(\" | \")\n",
    "                triple = (triple[0], triple[1], triple[2])\n",
    "                triples.append(triple)\n",
    "\n",
    "            triples.sort(key=lambda x: x[1])\n",
    "            for triple in triples:\n",
    "                mtriples += triple[0] + \" \" + triple[1] + \" \" + triple[2] + \" \"\n",
    "                        \n",
    "            # Rimuovi l'ultimo spazio, se presente\n",
    "            mtriples = mtriples.rstrip()\n",
    "            mts.append(mtriples)\n",
    "\n",
    "        # Filtra solo le frasi con lingua 'it-PE'\n",
    "        lexs = [lex.text for lex in entry.iter('lex') if lex.get('lang') == 'it-PE']\n",
    "\n",
    "        # Assicurati che mts e lexs abbiano valori predefiniti\n",
    "        mts = mts if mts else [\"\"]\n",
    "        lexs = lexs if lexs else [\"\"]\n",
    "\n",
    "        dataset.append([size, file_name, eid, category, shape, shape_type, mts[0], lexs])\n",
    "\n",
    "# Converti direttamente in un DataFrame\n",
    "df_dataset = pd.DataFrame(dataset, columns=[\"num_triples\", \"file_name\", \"eid\", \"category\", \"shape\", \"shape_type\", \"data_unit\", \"sentence\"])\n",
    "\n",
    "# Salva il DataFrame in un file CSV\n",
    "df_dataset.to_csv(\"datasets\\\\it-PE\\\\test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
