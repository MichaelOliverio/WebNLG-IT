{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "#bleu \n",
    "from evaluate import load\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "#ter\n",
    "from torchmetrics.text import TranslationEditRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open files in generations directory\n",
    "def open_files(directory):\n",
    "    files = os.listdir(directory)\n",
    "    files.sort()\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "files = open_files('generations')\n",
    "for file in files:\n",
    "    dataset = pd.read_csv('generations/' + file)\n",
    "    datasets[file] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta-llama2_7b_en_2epoch_decoding.csv',\n",
       " 'meta-llama2_7b_it_2epoch_decoding.csv',\n",
       " 't5-large_en_2epoch_decoding.csv',\n",
       " 't5-large_it_2epoch_decoding.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione automatica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sacrebleu = load(\"sacrebleu\")\n",
    "\n",
    "def blue_evaluation(df):\n",
    "    blue_scores = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        reference = df['actuals'][i].lower()\n",
    "        candidate = df['predictions'][i].lower()\n",
    "\n",
    "        blue_score = sacrebleu.compute(predictions=[candidate], references=[reference])\n",
    "        blue_scores.append(float(blue_score['score']))\n",
    "        \n",
    "    return blue_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU SCORES: \n",
      "\n",
      "- meta-llama2_7b_en_2epoch_decoding.csv:\n",
      "    33.89323112544573\n",
      "\n",
      "\n",
      "- meta-llama2_7b_it_2epoch_decoding.csv:\n",
      "    31.891374150401013\n",
      "\n",
      "\n",
      "- t5-large_en_2epoch_decoding.csv:\n",
      "    32.70961019679847\n",
      "\n",
      "\n",
      "- t5-large_it_2epoch_decoding.csv:\n",
      "    29.922332667730085\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('BLEU SCORES: \\n')\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(f'- {dataset_name}:')\n",
    "\n",
    "    datasets[dataset_name]['bleu_score'] = blue_evaluation(datasets[dataset_name])\n",
    "    print(f'    {datasets[dataset_name]['bleu_score'].mean()}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "def bertscore_evaluation(actual, prediction, lang):\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        predictions.append(prediction.iloc[i].lower())\n",
    "        references.append(actual.iloc[i].lower())\n",
    "\n",
    "    bertscore_scores = bertscore.compute(predictions=predictions, references=references, lang=lang)\n",
    "\n",
    "    return bertscore_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERTSCORE SCORES: \n",
      "\n",
      "- meta-llama2_7b_en_2epoch_decoding.csv (en):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-F1:  0.9430238373875618\n",
      "-P:  0.9452727970480919\n",
      "-R:  0.9408732368350029\n",
      "\n",
      "\n",
      "- meta-llama2_7b_it_2epoch_decoding.csv (it):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-F1:  0.8600391951203347\n",
      "-P:  0.8634315873980523\n",
      "-R:  0.857119910299778\n",
      "\n",
      "\n",
      "- t5-large_en_2epoch_decoding.csv (en):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-F1:  0.9407918038964271\n",
      "-P:  0.9440240755677223\n",
      "-R:  0.9376756454706192\n",
      "\n",
      "\n",
      "- t5-large_it_2epoch_decoding.csv (it):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\micha\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-F1:  0.8564814774990082\n",
      "-P:  0.8602060106992722\n",
      "-R:  0.8532467696666718\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('BERTSCORE SCORES: \\n')\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    #check if dataset contain substring en\n",
    "    if 'en' in dataset_name:\n",
    "        lang = 'en'\n",
    "    else:\n",
    "        lang = 'it'\n",
    "\n",
    "    print(f'- {dataset_name} ({lang}):')\n",
    "\n",
    "    score = bertscore_evaluation(datasets[dataset_name]['actuals'], datasets[dataset_name]['predictions'], lang)\n",
    "    datasets[dataset_name]['bertscore_f1'] = score['f1']\n",
    "    datasets[dataset_name]['bertscore_precision'] = score['precision']\n",
    "    datasets[dataset_name]['bertscore_recall'] = score['recall']\n",
    "    #print(score)\n",
    "    \n",
    "    print(f'-F1: ', np.mean(score['f1']))\n",
    "    print(f'-P: ', np.mean(score['precision']))\n",
    "    print(f'-R: ', np.mean(score['recall']))\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ter = TranslationEditRate()\n",
    "\n",
    "def ter_evaluation(actual, prediction):\n",
    "    ter_scores = []\n",
    "\n",
    "    for i in range(len(actual)):\n",
    "        reference = actual.iloc[i].lower()\n",
    "        candidate = prediction.iloc[i].lower()\n",
    "\n",
    "        ter_score = ter(candidate, [reference])\n",
    "        ter_scores.append(ter_score)\n",
    "\n",
    "    return ter_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TER SCORES: \n",
      "\n",
      "- meta-llama2_7b_en_2epoch_decoding.csv:\n",
      "    0.5982618408203125\n",
      "\n",
      "\n",
      "- meta-llama2_7b_it_2epoch_decoding.csv:\n",
      "    0.696801513671875\n",
      "\n",
      "\n",
      "- t5-large_en_2epoch_decoding.csv:\n",
      "    0.6065496215820313\n",
      "\n",
      "\n",
      "- t5-large_it_2epoch_decoding.csv:\n",
      "    0.6736116943359375\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('TER SCORES: \\n')\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(f'- {dataset_name}:')\n",
    "    datasets[dataset_name]['ter'] = ter_evaluation(datasets[dataset_name]['actuals'], datasets[dataset_name]['predictions'])\n",
    "    print(f'    {datasets[dataset_name]['ter'].mean()}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrf = load(\"chrf\")\n",
    "\n",
    "def chrf_evaluation(actual, prediction):\n",
    "    chrf_scores = []\n",
    "\n",
    "    # Utilizza tqdm per monitorare lo stato di avanzamento\n",
    "    for i in tqdm(range(len(actual)), desc=\"Calcolo CHRF\"):\n",
    "        reference = actual.iloc[i].lower()\n",
    "        candidate = prediction.iloc[i].lower()\n",
    "        chrf_score = chrf.compute(predictions=[candidate], references=[reference])['score']\n",
    "\n",
    "        chrf_scores.append(chrf_score)\n",
    "\n",
    "    return chrf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHRF SCORES: \n",
      "\n",
      "- meta-llama2_7b_en_2epoch_decoding.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo CHRF: 100%|██████████| 1000/1000 [00:10<00:00, 97.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    65.7996098209086\n",
      "\n",
      "\n",
      "- meta-llama2_7b_it_2epoch_decoding.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo CHRF: 100%|██████████| 1000/1000 [00:10<00:00, 91.76it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    62.61171393131402\n",
      "\n",
      "\n",
      "- t5-large_en_2epoch_decoding.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo CHRF: 100%|██████████| 1000/1000 [00:09<00:00, 105.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    64.57947403011968\n",
      "\n",
      "\n",
      "- t5-large_it_2epoch_decoding.csv:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calcolo CHRF: 100%|██████████| 1000/1000 [00:10<00:00, 98.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    61.121502896977965\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('CHRF SCORES: \\n')\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    print(f'- {dataset_name}:')\n",
    "    datasets[dataset_name]['chrf'] = chrf_evaluation(datasets[dataset_name]['actuals'], datasets[dataset_name]['predictions'])\n",
    "    print(f'    {datasets[dataset_name]['chrf'].mean()}')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>triples</th>\n",
       "      <th>predictions</th>\n",
       "      <th>actuals</th>\n",
       "      <th>bleu_score</th>\n",
       "      <th>bertscore_f1</th>\n",
       "      <th>bertscore_precision</th>\n",
       "      <th>bertscore_recall</th>\n",
       "      <th>ter</th>\n",
       "      <th>chrf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11th_Mississippi_Infantry_Monument category Co...</td>\n",
       "      <td>The 11th Mississippi Infantry Monument is loca...</td>\n",
       "      <td>A monument to the 11th Mississippi Infantry, w...</td>\n",
       "      <td>31.735182</td>\n",
       "      <td>0.941381</td>\n",
       "      <td>0.942412</td>\n",
       "      <td>0.940351</td>\n",
       "      <td>tensor(0.6571)</td>\n",
       "      <td>71.089044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bananaman broadcastedBy BBC BBC city Broadcast...</td>\n",
       "      <td>Bananaman, starring Bill Oddie, was broadcast ...</td>\n",
       "      <td>Bill Oddie stars in a BBC programme called Ban...</td>\n",
       "      <td>7.363124</td>\n",
       "      <td>0.895899</td>\n",
       "      <td>0.896028</td>\n",
       "      <td>0.895769</td>\n",
       "      <td>tensor(0.8889)</td>\n",
       "      <td>45.632178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Karlsruhe postalCode 76131–76229</td>\n",
       "      <td>The postal codes for Karlsruhe are 76131–76229.</td>\n",
       "      <td>The postal codes of Karlsruhe are 76131–76229.</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.993597</td>\n",
       "      <td>0.993597</td>\n",
       "      <td>0.993597</td>\n",
       "      <td>tensor(0.1429)</td>\n",
       "      <td>88.130745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turkish_people religion Irreligion</td>\n",
       "      <td>The Turkish people are Irreligious.</td>\n",
       "      <td>Some Turkish people are irreligious.</td>\n",
       "      <td>75.983569</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>tensor(0.2000)</td>\n",
       "      <td>90.411086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENAIRE city Madrid Adolfo_Suárez_Madrid–Baraja...</td>\n",
       "      <td>Adolfo Suarez Madrid-Barajas Airport is locate...</td>\n",
       "      <td>The Adolfo Suarez Madrid-Barajas airport is op...</td>\n",
       "      <td>37.514537</td>\n",
       "      <td>0.953546</td>\n",
       "      <td>0.958903</td>\n",
       "      <td>0.948248</td>\n",
       "      <td>tensor(0.5484)</td>\n",
       "      <td>69.168244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>ALCO_RS-3 buildDate \"May 1950 - August 1956\" A...</td>\n",
       "      <td>The ALCO RS-3 was built between May 1950 and A...</td>\n",
       "      <td>The ALCO RS-3 produced between May 1950 and Au...</td>\n",
       "      <td>51.795975</td>\n",
       "      <td>0.975178</td>\n",
       "      <td>0.972941</td>\n",
       "      <td>0.977425</td>\n",
       "      <td>tensor(0.2632)</td>\n",
       "      <td>76.764512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Super_Capers budget 2000000.0 Super_Capers dir...</td>\n",
       "      <td>Super Capers, starring Justin Whalin, was dist...</td>\n",
       "      <td>Super Capers is a 98 minute film that was dist...</td>\n",
       "      <td>35.282778</td>\n",
       "      <td>0.941008</td>\n",
       "      <td>0.943822</td>\n",
       "      <td>0.938210</td>\n",
       "      <td>tensor(0.5882)</td>\n",
       "      <td>68.502208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>It's_Great_to_Be_Young_(1956_film) editing Max...</td>\n",
       "      <td>The film \"It's Great to Be Young\" (1956) was e...</td>\n",
       "      <td>It's Great to Be Young was edited by Max Bened...</td>\n",
       "      <td>46.606087</td>\n",
       "      <td>0.906294</td>\n",
       "      <td>0.893222</td>\n",
       "      <td>0.919754</td>\n",
       "      <td>tensor(0.5000)</td>\n",
       "      <td>86.557185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Lady_Anne_Monson deathDate 1776-02-18 Lady_Ann...</td>\n",
       "      <td>Lady Anne Monson was a national of the Kingdom...</td>\n",
       "      <td>Lady Anne Monson married George Monson was a B...</td>\n",
       "      <td>13.330451</td>\n",
       "      <td>0.944976</td>\n",
       "      <td>0.944121</td>\n",
       "      <td>0.945832</td>\n",
       "      <td>tensor(0.7600)</td>\n",
       "      <td>54.476607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Brandon_Carter almaMater University_of_Cambrid...</td>\n",
       "      <td>Brandon Carter was born in England and his alm...</td>\n",
       "      <td>David Sainsbury (Baron Sainsbury of Turville) ...</td>\n",
       "      <td>21.163412</td>\n",
       "      <td>0.913055</td>\n",
       "      <td>0.914545</td>\n",
       "      <td>0.911569</td>\n",
       "      <td>tensor(1.0357)</td>\n",
       "      <td>66.066162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               triples  \\\n",
       "0    11th_Mississippi_Infantry_Monument category Co...   \n",
       "1    Bananaman broadcastedBy BBC BBC city Broadcast...   \n",
       "2                    Karlsruhe postalCode 76131–76229    \n",
       "3                  Turkish_people religion Irreligion    \n",
       "4    ENAIRE city Madrid Adolfo_Suárez_Madrid–Baraja...   \n",
       "..                                                 ...   \n",
       "995  ALCO_RS-3 buildDate \"May 1950 - August 1956\" A...   \n",
       "996  Super_Capers budget 2000000.0 Super_Capers dir...   \n",
       "997  It's_Great_to_Be_Young_(1956_film) editing Max...   \n",
       "998  Lady_Anne_Monson deathDate 1776-02-18 Lady_Ann...   \n",
       "999  Brandon_Carter almaMater University_of_Cambrid...   \n",
       "\n",
       "                                           predictions  \\\n",
       "0    The 11th Mississippi Infantry Monument is loca...   \n",
       "1    Bananaman, starring Bill Oddie, was broadcast ...   \n",
       "2      The postal codes for Karlsruhe are 76131–76229.   \n",
       "3                  The Turkish people are Irreligious.   \n",
       "4    Adolfo Suarez Madrid-Barajas Airport is locate...   \n",
       "..                                                 ...   \n",
       "995  The ALCO RS-3 was built between May 1950 and A...   \n",
       "996  Super Capers, starring Justin Whalin, was dist...   \n",
       "997  The film \"It's Great to Be Young\" (1956) was e...   \n",
       "998  Lady Anne Monson was a national of the Kingdom...   \n",
       "999  Brandon Carter was born in England and his alm...   \n",
       "\n",
       "                                               actuals  bleu_score  \\\n",
       "0    A monument to the 11th Mississippi Infantry, w...   31.735182   \n",
       "1    Bill Oddie stars in a BBC programme called Ban...    7.363124   \n",
       "2       The postal codes of Karlsruhe are 76131–76229.   50.000000   \n",
       "3                 Some Turkish people are irreligious.   75.983569   \n",
       "4    The Adolfo Suarez Madrid-Barajas airport is op...   37.514537   \n",
       "..                                                 ...         ...   \n",
       "995  The ALCO RS-3 produced between May 1950 and Au...   51.795975   \n",
       "996  Super Capers is a 98 minute film that was dist...   35.282778   \n",
       "997  It's Great to Be Young was edited by Max Bened...   46.606087   \n",
       "998  Lady Anne Monson married George Monson was a B...   13.330451   \n",
       "999  David Sainsbury (Baron Sainsbury of Turville) ...   21.163412   \n",
       "\n",
       "     bertscore_f1  bertscore_precision  bertscore_recall             ter  \\\n",
       "0        0.941381             0.942412          0.940351  tensor(0.6571)   \n",
       "1        0.895899             0.896028          0.895769  tensor(0.8889)   \n",
       "2        0.993597             0.993597          0.993597  tensor(0.1429)   \n",
       "3        0.998647             0.998647          0.998647  tensor(0.2000)   \n",
       "4        0.953546             0.958903          0.948248  tensor(0.5484)   \n",
       "..            ...                  ...               ...             ...   \n",
       "995      0.975178             0.972941          0.977425  tensor(0.2632)   \n",
       "996      0.941008             0.943822          0.938210  tensor(0.5882)   \n",
       "997      0.906294             0.893222          0.919754  tensor(0.5000)   \n",
       "998      0.944976             0.944121          0.945832  tensor(0.7600)   \n",
       "999      0.913055             0.914545          0.911569  tensor(1.0357)   \n",
       "\n",
       "          chrf  \n",
       "0    71.089044  \n",
       "1    45.632178  \n",
       "2    88.130745  \n",
       "3    90.411086  \n",
       "4    69.168244  \n",
       "..         ...  \n",
       "995  76.764512  \n",
       "996  68.502208  \n",
       "997  86.557185  \n",
       "998  54.476607  \n",
       "999  66.066162  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['llama2_7b_en_2epoch_decoding.csv']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
